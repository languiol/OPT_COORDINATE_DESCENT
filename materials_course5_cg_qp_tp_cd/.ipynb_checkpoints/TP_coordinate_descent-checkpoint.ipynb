{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Proximal coordinate descent method on regression models\n",
    "\n",
    "#### Authors: S. Gaiffas, A. Gramfort\n",
    "\n",
    "## Aim\n",
    "\n",
    "The aim of this material is to code \n",
    "- proximal coordinate descent\n",
    "\n",
    "for \n",
    "- Lasso / L1 linear regression\n",
    "- non-negative least squares (NNLS)\n",
    "\n",
    "models.\n",
    "\n",
    "The proximal operators we will use are the \n",
    "- L1 penalization\n",
    "- indicator function of $\\mathbb{R}_+$\n",
    "\n",
    "## VERY IMPORTANT\n",
    "\n",
    "- This work **must be done by pairs of students**.\n",
    "- **Each** student must send their work **before the 23th of october at 23:59**, using the **moodle platform**.\n",
    "- This means that **each student in the pair sends the same file**\n",
    "- On the moodle, in the \"Optimization for Data Science\" course, you have a \"devoir\" section called **Rendu TP du 17 octobre 2016**. This is where you submit your jupyter notebook file. \n",
    "- The **name of the file must be** constructed as in the next cell\n",
    "\n",
    "# Gentle reminder: no evaluation if you don't respect this EXACTLY\n",
    "\n",
    "### How to construct the name of your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp_cd_gaiffas_stephane_and_gramfort_alexandre.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Change here using YOUR first and last names\n",
    "fn1 = \"stephane\"\n",
    "ln1 = \"gaiffas\"\n",
    "fn2 = \"alexandre\"\n",
    "ln2 = \"gramfort\"\n",
    "\n",
    "filename = \"_\".join(map(lambda s: s.strip().lower(), \n",
    "                        [\"tp_cd\", ln1, fn1, \"and\", ln2, fn2])) + \".ipynb\"\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## to embed figures in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0 : Introduction\n",
    "\n",
    "We'll start by generating sparse positive vectors and simulating data\n",
    "\n",
    "### Getting sparse coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=2)  # to have simpler print outputs with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11017f5d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEKCAYAAADticXcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns2LkxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1101095d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_features = 50\n",
    "n_samples = 1000\n",
    "idx = np.arange(n_features)\n",
    "coefs = (idx % 2) * np.exp(-idx / 10.)\n",
    "coefs[20:] = 0.\n",
    "plt.stem(coefs)\n",
    "plt.title(\"Parameters / Coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for the simulation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import multivariate_normal\n",
    "from scipy.linalg.special_matrices import toeplitz\n",
    "from numpy.random import randn\n",
    "\n",
    "\n",
    "def simu_linreg(coefs, n_samples=1000, corr=0.5):\n",
    "    \"\"\"Simulation of a linear regression model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coefs : `numpy.array`, shape=(n_features,)\n",
    "        Coefficients of the model\n",
    "    \n",
    "    n_samples : `int`, default=1000\n",
    "        Number of samples to simulate\n",
    "    \n",
    "    corr : `float`, default=0.5\n",
    "        Correlation of the features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A : `numpy.ndarray`, shape=(n_samples, n_features)\n",
    "        Simulated features matrix. It samples of a centered Gaussian \n",
    "        vector with covariance given by the Toeplitz matrix\n",
    "    \n",
    "    b : `numpy.array`, shape=(n_samples,)\n",
    "        Simulated labels\n",
    "    \"\"\"\n",
    "    # Construction of a covariance matrix\n",
    "    cov = toeplitz(corr ** np.arange(0, n_features))\n",
    "    # Simulation of features\n",
    "    A = multivariate_normal(np.zeros(n_features), cov, size=n_samples)\n",
    "    # Simulation of the labels\n",
    "    b = A.dot(coefs) + randn(n_samples)\n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximal operators and Solver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remind that the proximal operator of a fonction $g$ is given by:\n",
    "\n",
    "$$\n",
    "\\text{prox}_g(y, t) = \\arg\\min_x \\Big\\{ \\frac 12 \\|x - y\\|_2^2 + t g(x) \\Big\\}.\n",
    "$$\n",
    "\n",
    "where $t \\geq 0$ is a non-negative number.\n",
    "We have in mind to use the following cases\n",
    "\n",
    "- Lasso penalization, where $g(x) = s \\|x\\|_1$\n",
    "- Indicator function of $\\mathbb{R}_+$, where $g(x) = i_{x \\geq 0}(\\cdot)$\n",
    "\n",
    "where $s \\geq 0$ is a regularization parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to minimize:\n",
    "$$\n",
    "\\arg\\min_x F(x)\n",
    "$$\n",
    "with\n",
    "$$\n",
    " F(x) = \\frac{1}{2} \\|b - Ax\\|^2 + g(x)\n",
    "$$\n",
    "\n",
    "## Questions\n",
    "\n",
    "- Code a function that computes $g(x)$ and $\\text{prox}_g(x)$ for in both cases\n",
    "- Justify why proximal coordinate descent can be applied to obtain a minimum of such objective functions.\n",
    "- Starting from the code provided in the notebook presented during the coordinate descent course as well as the code below, implement a proximal coordinate method for both penalties.\n",
    "- Evaluate qualitatively the convergence when varying the conditioning of the problem.\n",
    "- Bonus: Try to show that coordinate is much less affected by bad conditioning that proximal gradient descent.\n",
    "\n",
    "### You are expected to implement the smart residuals updates !\n",
    "\n",
    "### You are very welcome to reuse everything you did for TP1 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cd_linreg(x0, A, b, g, prox_g, s=0., n_iter=50,\n",
    "              x_true=coefs, verbose=True):\n",
    "    \"\"\"Proximal gradient descent algorithm\n",
    "\n",
    "    Minimize :\n",
    "    \n",
    "    1/2 ||b−Ax||^2 + s * g(x)\n",
    "    \n",
    "    with coodinate descent.\n",
    "    \"\"\"\n",
    "    x = x0.copy()\n",
    "    x_new = x0.copy()\n",
    "    n_samples, n_features = A.shape\n",
    "\n",
    "    # estimation error history\n",
    "    errors = []\n",
    "    # objective history\n",
    "    objectives = []\n",
    "    # Current estimation error\n",
    "    err = norm(x - x_true) / norm(x_true)\n",
    "    errors.append(err)\n",
    "    # Current objective\n",
    "    obj = 0.5 * linalg.norm(b - A.dot(x))**2 + g(x, s)\n",
    "    objectives.append(obj)\n",
    "\n",
    "    if verbose:\n",
    "        print \"Lauching Coordinate Descent solver...\"\n",
    "        print ' | '.join([name.center(8) for name in [\"it\", \"obj\", \"err\"]])\n",
    "\n",
    "    for k in range(n_iter + 1):\n",
    "\n",
    "        #### TODO ####\n",
    "        \n",
    "        obj = 0.5 * linalg.norm(b - A.dot(x))**2 + g(x, s)\n",
    "        err = norm(x - x_true) / norm(x_true)\n",
    "        errors.append(err)\n",
    "        objectives.append(obj)\n",
    "        if k % 10 == 0 and verbose:\n",
    "            print ' | '.join([(\"%d\" % k).rjust(8), \n",
    "                              (\"%.2e\" % obj).rjust(8), \n",
    "                              (\"%.2e\" % err).rjust(8)])\n",
    "    return x, objectives, errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
